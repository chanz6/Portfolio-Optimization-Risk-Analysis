{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data & add daily returns column\n",
    "def import_data(stocks):\n",
    "    stocks_data = {}\n",
    "    for stock in stocks:\n",
    "        stock_data = yf.download(stock, start='2010-01-01', end='2025-01-01')\n",
    "        stock_data['Return'] = stock_data['Close'].pct_change()\n",
    "        stocks_data[stock] = stock_data\n",
    "    return stocks_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Calculate Annual Expected Return of an Asset**:\n",
    "\n",
    "The annual expected return for an asset i is calculated as follows _(assuming 252 trading days)_:\n",
    "$$E(R_{annual}) = (1 + E(R_{daily}))^{252} - 1$$\n",
    "where,\n",
    "$$E(R_{daily}) = \\frac{\\displaystyle\\sum R_t}{n}$$\n",
    "and $R_t$ is the return on day $t$ (daily return).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate annual expected return\n",
    "def annual_expected_return(data):\n",
    "    results_dict = {}\n",
    "    # calculate expected daily return\n",
    "    returns_data = pd.DataFrame({stock: data[stock]['Return'] for stock in data.keys()})\n",
    "    e_daily_returns = np.sum(returns_data, axis=0) / len(returns_data)\n",
    "    # calculate expected annual return\n",
    "    e_annual_returns = (1 + e_daily_returns)**252 - 1\n",
    "    # record results\n",
    "    results_dict['Daily Returns'] = e_daily_returns\n",
    "    results_dict['Annual Returns'] = e_annual_returns\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Calculate Expected Portfolio Return**:\n",
    "\n",
    "The expected portfolio return is calculated as:\n",
    "$$E(R_p) = \\displaystyle\\sum (\\omega_i \\times E(R_i))$$\n",
    "where:\n",
    "- $E(R_p)$ = Expected return of the portfolio (in 1 year)\n",
    "- $\\omega_i$ = Weight (proportion) of asset i in the portfolio\n",
    "- $E (R_i)$ = Expected return of asset i\n",
    "- $n$ = Number of assets in the portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_return(data, weights):\n",
    "    # extract expected annual returns\n",
    "    e_annual = annual_expected_return(data)\n",
    "    e_annual_returns = np.array(e_annual['Annual Returns'].values)\n",
    "    # compute expected portfolio return\n",
    "    return sum(weights[i] * e_annual_returns[i] for i in range(len(weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "#### **3. Calculate Volatility**:\n",
    "\n",
    "The annualized volatility for an asset i is calculated as follows _(assuming 252 trading days)_:\n",
    "$$\\sigma_{annual} = \\sigma_{daily} \\times \\sqrt{252}$$\n",
    "where $\\sigma_{daily}$ is defined as:\n",
    "$$\\sigma_{daily} = \\sqrt{\\frac{\\displaystyle\\sum (R_t - \\hat{R})^2}{n-1}}$$\n",
    "where:\n",
    "- $R_t$: Daily return on day $t$\n",
    "- $\\hat{R}$: Average daily returns\n",
    "- $n$: Number of trading days\n",
    "\n",
    "Portfolio volatility $\\sigma_p$ is calculated as follows:\n",
    "$$\\sigma_p = \\sqrt{\\omega^T \\gamma \\omega}$$\n",
    "where:\n",
    "- $\\omega$ = Portfolio weights (vector of size n)\n",
    "- $\\gamma$ = Annualized covariace matrix (constructed using annualized volatilities and correlations)\n",
    "- $\\omega^T$ = Transpose of weights vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate annualized volatility\n",
    "def annualized_volatility(data):\n",
    "    results_dict = {}\n",
    "    # compute average daily returns\n",
    "    returns_data = pd.DataFrame({stock: data[stock]['Return'] for stock in data.keys()})\n",
    "    # compute standard deviation of daily returns\n",
    "    volatility_daily = returns_data.std()\n",
    "    # compute annualized volatility\n",
    "    volatility_annualized = volatility_daily * np.sqrt(252)\n",
    "    # record results\n",
    "    results_dict['Daily Volatility'] = volatility_daily\n",
    "    results_dict['Anual Volatility'] = volatility_annualized\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate portfolio volatility\n",
    "def portfolio_volatility(data, weights):\n",
    "    returns_data = pd.DataFrame({stock: data[stock]['Return'] for stock in data.keys()})\n",
    "    returns_data.dropna(inplace=True)\n",
    "    # compute covariance matrix\n",
    "    daily_cov = np.cov(returns_data, rowvar=False)\n",
    "    annualized_cov = daily_cov * 252\n",
    "    # convert weights & volatilities to arrays\n",
    "    w = np.array(weights)\n",
    "    wT = np.transpose(w)\n",
    "    # compute portfolio volatility\n",
    "    return np.sqrt(np.dot(wT, np.dot(annualized_cov, w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Sharpe Ratio:**\n",
    "$$\\text{Sharpe Ratio} = \\frac{\\text{Portfolio Return - Risk Free Rate}}{\\text{Portfolio Volatility}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(data, weights):\n",
    "    results_dict = {}\n",
    "    p_return = portfolio_return(data, weights)\n",
    "    rfr = 0.04 # 4% (U.S. Treasury Yield)\n",
    "    p_volatility = portfolio_volatility(data, weights)\n",
    "    # compute sharpe ratio\n",
    "    return (p_return - rfr) / p_volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Gradient of the Sharpe Ratio**:\n",
    "\n",
    "We wish to find the gradient of the sharpe ratio formula.\n",
    "\n",
    "**Sharpe Ratio Formula**:\n",
    "$$\\text{Sharpe Ratio} = \\frac{E(R_p) - R_f}{\\sigma_p}$$\n",
    "\n",
    "where:\n",
    "- $E(R_p) = \\bold{w^T}\\mu$ (Expected Portfolio Return)\n",
    "- $R_f =$ risk-free rate (assumed to be 0.04)\n",
    "- $\\sigma_p = \\sqrt{\\bold{w^T}\\gamma\\bold{w}}$ (Portfolio Volatility)\n",
    "- $\\bold{w} =$ Vector of portfolio weights\n",
    "- $\\mu =$ Vector of expected returns\n",
    "- $\\gamma =$ Covariance matrix of stock returns\n",
    "\n",
    "We begin by computing partial derivatives.\n",
    "\n",
    "**Gradient of Portfolio Return $E(R_p)$**:\n",
    "$$\\frac{\\partial E(R_p)}{\\partial\\bold{w}} = \\mu$$\n",
    "\n",
    "**Gradient of Portfolio Volatility $\\sigma_p$**:\n",
    "$$\\frac{\\partial\\sigma_p}{\\partial\\bold{w}} = \\frac{\\gamma\\bold{w}}{\\sigma_p}$$\n",
    "\n",
    "Thus we have,\n",
    "\n",
    "**Gradient of the Sharpe Ratio**:\n",
    "$$\\nabla SR = \\frac{\\frac{\\partial E(R_p)}{\\partial\\bold{w}}\\cdot\\sigma_p - E(R_p)\\cdot\\frac{\\partial\\sigma_p}{\\partial\\bold{w}}}{\\sigma_p^2} = \\frac{\\mu\\sigma_p - E(R_p)\\cdot\\frac{\\gamma\\bold{w}}{\\sigma_p}}{\\sigma_p^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio_gradient(data, weights):\n",
    "    p_return = portfolio_return(data, weights)\n",
    "    p_volatility = portfolio_volatility(data, weights)\n",
    "    # compute mu (vector of expected returns)\n",
    "    mu = np.array(annual_expected_return(data)['Annual Returns'].values)\n",
    "    # compute gamma (covariance matrix of stock returns)\n",
    "    returns_data = pd.DataFrame({stock: data[stock]['Return'] for stock in data.keys()})\n",
    "    returns_data.dropna(inplace=True)\n",
    "    daily_cov = np.cov(returns_data, rowvar=False)\n",
    "    gamma = daily_cov * 252\n",
    "    # compute gradient\n",
    "    dE = mu\n",
    "    dsigma = np.dot(gamma, weights) / p_volatility\n",
    "    grad_sharpe = (dE * p_volatility - p_return * dsigma) / (p_volatility)**2\n",
    "\n",
    "    return grad_sharpe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Gradient Ascent**:\n",
    "\n",
    "For portfolio optimization, we use a **gradient ascent** algorithm to maximize the **Sharpe Ratio** by iteratively adjusting asset allocations.\n",
    "\n",
    "1. **Gradient Calculation**: The algorithm computes the gradient at the current `weights` position, indicating the direction of the steepest increase in Sharpe Ratio.\n",
    "2. **Regularization**: To encourage portfolio diversification, an L2 regularization term is applied to the gradient. Without this, the algorithm may exploit the Sharpe Ratio formula by concentrating allocations in high-return assets while disregarding lower-risk investments.\n",
    "3. **Weight Update**: The portfolio weights are adjusted in the direction of the gradient to improve the Sharpe Ratio.\n",
    "4. **Projection**: The updated weights are projected onto the simplex to ensure all values remain **non-negative** and **sum to 1**, further promoting a well-diversified portfolio.\n",
    "5. **Iterative Optimization**: Steps 1-4 are repeated for `num_iterations` until weights converge to an optimal Sharpe Ratio.\n",
    "\n",
    "### **Additional Features**:\n",
    "- **Step Size Decay**: The learning rate (`alpha`) is reduced by a factor of `decay` after each iteration, improving convergence stability and preventing overshooting.\n",
    "- **Early Stopping Condition**: If the Sharpe Ratio decreases for **5 consecutive iterations**, the algorithm terminates early to prevent unnecessary computations and potential degradation of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection to simplex (ensure all weights are non-negative and sum to 1)\n",
    "def project_to_simplex(weights, epsilon=1e-4, lambda_reg=0.01):\n",
    "    # Ensure weights have a minimum value to prevent zero allocations\n",
    "    weights = np.maximum(weights, epsilon)\n",
    "\n",
    "    # Apply L2 regularization to prevent extreme allocations\n",
    "    weights -= lambda_reg * weights\n",
    "\n",
    "    # Sort weights in descending order for projection\n",
    "    sorted_weights = np.sort(weights)[::-1]\n",
    "    cumulative_sum = np.cumsum(sorted_weights) - 1  # Adjust for sum constraint\n",
    "\n",
    "    # Find the largest rho index that satisfies the condition\n",
    "    rho = np.where(sorted_weights - (cumulative_sum / (np.arange(len(weights)) + 1)) > 0)[0][-1]\n",
    "    lambda_ = cumulative_sum[rho] / (rho + 1)\n",
    "\n",
    "    # Project weights onto the simplex while ensuring a minimum threshold\n",
    "    projected_weights = np.maximum(weights - lambda_, epsilon)\n",
    "\n",
    "    # Normalize to sum to 1\n",
    "    return projected_weights / np.sum(projected_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement gradient ascent to maximize the Sharpe Ratio\n",
    "def portfolio_optimization(data, weights, alpha=0.5, decay=0.99, num_iterations=200, lambda_reg=0.05, patience=7):\n",
    "    recent_sharpe = -np.inf\n",
    "    counter = 0\n",
    "    results = {'Iteration': [0], \n",
    "               'Sharpe Ratio': [sharpe_ratio(data, weights)],\n",
    "    }\n",
    "    for i in range(num_iterations):\n",
    "        grad_sharpe = sharpe_ratio_gradient(data, weights)\n",
    "        # apply regularization to avoid extreme weights\n",
    "        grad_sharpe -= lambda_reg * np.array(weights)\n",
    "        # update gradient ascent\n",
    "        weights += alpha * grad_sharpe\n",
    "        # projection with bias to prevent zero weights\n",
    "        weights = project_to_simplex(weights)\n",
    "        # decay\n",
    "        alpha *= decay\n",
    "        # print results\n",
    "        sharpe = sharpe_ratio(data, weights)\n",
    "        # print(weights)\n",
    "        # print(sharpe)\n",
    "        # record results\n",
    "        results['Iteration'].append(i+1)\n",
    "        results['Sharpe Ratio'].append(sharpe)\n",
    "        # check for sharpe ratio decrease\n",
    "        if sharpe < recent_sharpe:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                # print('There was 5 consecutive decreases in Sharpe Ratio, Terminating...')\n",
    "                break\n",
    "        else:\n",
    "            recent_sharpe = sharpe\n",
    "            counter = 0\n",
    "\n",
    "    results['Optimal Portfolio'] = pd.Series(weights, index=list(data.keys()))\n",
    "    display = results['Optimal Portfolio'].map(lambda x: f\"{x * 100:.2f}%\")\n",
    "\n",
    "    print('Total Iterations Completed: ' + str(max(results['Iteration'])))\n",
    "    print('Sharpe Ratio: ' + str(sharpe))\n",
    "    print('Computed Optimal Portfolio: \\n' + str(display))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Display Dashboard_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_analysis(stocks, weights, confidence_level = 0.95):\n",
    "    data = import_data(stocks)\n",
    "    returns_data = pd.DataFrame({stock: data[stock]['Return'] for stock in stocks})\n",
    "    returns_data.dropna(inplace=True)\n",
    "    metrics = {\n",
    "        'Metric': ['VaR', 'CVaR', 'Volatility', 'Return', 'Sharpe Ratio'],\n",
    "        'Value': []\n",
    "    }\n",
    "    # optimize portfolio\n",
    "    optimize = portfolio_optimization(data, weights, alpha=0.5)\n",
    "    optimized_weights = np.array(optimize['Optimal Portfolio'])\n",
    "    portfolio_returns = np.dot(returns_data, optimized_weights)\n",
    "    # plot convergence\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(optimize['Iteration'], optimize['Sharpe Ratio'], marker='o', color='blue', markersize='5', label='Sharpe Ratio')\n",
    "\n",
    "    plt.xlabel('Iteration', fontsize=12)\n",
    "    plt.ylabel('Sharpe Ratio', fontsize=12)\n",
    "    plt.title('Sharpe Ratio Convergence Over Iterations', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.show()\n",
    "    # compute VaR\n",
    "    var = np.percentile(portfolio_returns, 100 * (1 - confidence_level))\n",
    "    # compute CVaR\n",
    "    cvar = \"{:,.2%}\".format(portfolio_returns[portfolio_returns <= var].mean())\n",
    "    var = \"{:,.2%}\".format(var)\n",
    "    # compute portfolio volatility\n",
    "    p_volatility = \"{:,.2%}\".format(portfolio_volatility(data, optimized_weights))\n",
    "    # compute expected portfolio return\n",
    "    p_return = \"{:,.2%}\".format(portfolio_return(data, optimized_weights))\n",
    "    # compute sharpe ratio\n",
    "    sharpe = round(sharpe_ratio(data, optimized_weights), 2)\n",
    "    # record results and display\n",
    "    metrics['Value'].extend([var, cvar, p_volatility, p_return, sharpe])\n",
    "    display = pd.DataFrame.from_dict(metrics)\n",
    "    \n",
    "    return display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_analysis(stocks, weights, confidence_level = 0.95):\n",
    "    data = import_data(stocks)\n",
    "    returns_data = pd.DataFrame({stock: data[stock]['Return'] for stock in stocks})\n",
    "    returns_data.dropna(inplace=True)\n",
    "    portfolio_returns = np.dot(returns_data, weights)\n",
    "    metrics = {\n",
    "        'Metric': ['VaR', 'CVaR', 'Volatility', 'Return', 'Sharpe Ratio'],\n",
    "        'Value': []\n",
    "    }\n",
    "    # create corrolation matrix\n",
    "    corr = returns_data.corr()\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, square=True)\n",
    "    plt.title(\"Stock Returns Correlation Matrix\")\n",
    "    plt.show()\n",
    "    # compute VaR\n",
    "    var = np.percentile(portfolio_returns, 100 * (1 - confidence_level))\n",
    "    # compute CVaR\n",
    "    cvar = \"{:,.2%}\".format(portfolio_returns[portfolio_returns <= var].mean())\n",
    "    var = \"{:,.2%}\".format(var)\n",
    "    # compute portfolio volatility\n",
    "    p_volatility = \"{:,.2%}\".format(portfolio_volatility(data, weights))\n",
    "    # compute expected portfolio return\n",
    "    p_return = \"{:,.2%}\".format(portfolio_return(data, weights))\n",
    "    # compute sharpe ratio\n",
    "    sharpe = round(sharpe_ratio(data, weights), 2)\n",
    "    # record results and display\n",
    "    metrics['Value'].extend([var, cvar, p_volatility, p_return, sharpe])\n",
    "    display = pd.DataFrame.from_dict(metrics)\n",
    "    \n",
    "    return display"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
